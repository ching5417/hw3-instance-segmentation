{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mask R-CNN\n",
    "Configurations and data loading code for MS COCO.\n",
    "Copyright (c) 2017 Matterport, Inc.\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "Written by Waleed Abdulla\n",
    "Training on VOC Written by genausz(genausz@hotmail.com)\n",
    "-----------------------------------------------------------------------------------------\n",
    "Usage: import the module (see Jupyter notebooks for examples), or run from\n",
    "       the command line as such:\n",
    "    # Train a model from coco weights.\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=coco --year=2012\n",
    "    # Train a new model starting from ImageNet weights.\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=imagenet --year=2012\n",
    "    # Continue training a model that you had trained earlier\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=/path/to/weights.h5  --year=2012\n",
    "    # Continue training the last model you trained\n",
    "    python3 voc.py train --dataset=/path/to/VOCdevkit/ --model=last\n",
    "    # Run VOC inference on the last model you trained\n",
    "    python3 voc.py inference --dataset=/path/to/VOCdevkit/ --model=last --year=2012 --limit=50\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import cv2\n",
    "import imgaug\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "# Inference result directory\n",
    "RESULTS_DIR = os.path.abspath(\"./inference/\")  # 後面程式碼會自己產生這個資料夾\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn import visualize\n",
    "\n",
    "import matplotlib\n",
    "# Agg backend runs without a display\n",
    "matplotlib.use('Agg')  # 不知道是什麼\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "DEFAULT_DATASET_YEAR = '2012'  # 我可能不需要這個\n",
    "\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")  \n",
    "# 這邊之後要改，不能用coco pretrain的model\n",
    "\n",
    "\n",
    "# VOC DATASET MASK MAP FUNCTION\n",
    "# Following codes are mapping each mask color(SegmentationClass) to ground truth index.\n",
    "# - reference: https://d2l.ai/chapter_computer-vision/semantic-segmentation-and-dataset.html\n",
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'] #potted plant # tv/monitor\n",
    "\n",
    "def build_colormap2label():\n",
    "    \"\"\"Build a RGB color to label mapping for segmentation.\"\"\"\n",
    "    colormap2label = np.zeros(256 ** 3)\n",
    "    for i, colormap in enumerate(VOC_COLORMAP):\n",
    "        colormap2label[(colormap[0]*256 + colormap[1])*256 + colormap[2]] = i\n",
    "    return colormap2label\n",
    "\n",
    "def voc_label_indices(colormap, colormap2label):\n",
    "    \"\"\"Map a RGB color to a label.\"\"\"\n",
    "    colormap = colormap.astype('int32')\n",
    "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n",
    "           + colormap[:, :, 2])\n",
    "    return colormap2label[idx]\n",
    "# VOC DATASET MASK MAP FUNCTION\n",
    "\n",
    "\n",
    "class VocConfig(Config):\n",
    "    NAME = \"voc\"\n",
    "\n",
    "    IMAGE_PER_GPU = 2\n",
    "\n",
    "    NUM_CLASSES = 1 + 20 # VOC 2012 have 20 classes. \"1\" is for background.\n",
    "\n",
    "class InferenceConfig(VocConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 2\n",
    "    IMAGES_PER_GPU = 32  # 8 # 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0  # 這邊感覺可以調一下\n",
    "\n",
    "\n",
    "class VocDataset(utils.Dataset):\n",
    "    def load_voc(self, dataset_dir, trainval, year='2012'):  # year 2012應該可以拿掉\n",
    "        \"\"\"Load a voc_year of the VOC dataset.\n",
    "        dataset_dir: The root directory of the VOC dataset, example: '/mnt/disk1/VOCdevkit'\n",
    "        trainval: 'train' or 'val' for Training or Validation\n",
    "        year: '2007' or '2012' for VOC dataset\n",
    "        \"\"\"\n",
    "                \n",
    "        PATH = os.path.join(ROOT_DIR, \"dataset/pascal_train.json\")\n",
    "        voc_json = COCO(PATH) # load training annotations\n",
    "        image_ids = []\n",
    "        if trainval == 'train':\n",
    "            image_ids = list(voc_json.imgs.keys())[:1080]\n",
    "        else:\n",
    "            image_ids = list(voc_json.imgs.keys())[1080:]\n",
    "        for image_id in image_ids:\n",
    "            image_file_name = voc_json.imgs[736]['file_name']\n",
    "            image_dir_path = os.path.join(ROOT_DIR, \"dataset/train_images/\")\n",
    "            image_path = os.path.join(image_dir_path, image_file_name)\n",
    "            self.add_image(\"voc\",\n",
    "                            image_id=image_file_name,\n",
    "                            path=image_path)\n",
    "\n",
    "    def load_class_label(self, image_id):\n",
    "        '''Mapping SegmentationClass image's color to indice of ground truth \n",
    "        image_id: id of mask\n",
    "        Return:\n",
    "        class_label: [height, width] matrix contains values form 0 to 20\n",
    "        '''\n",
    "        PATH = os.path.join(ROOT_DIR, \"dataset/pascal_train.json\")\n",
    "        voc_json = COCO(PATH) # load training annotations\n",
    "        height = voc_json.imgs[image_id]['height']\n",
    "        width = voc_json.imgs[image_id]['width']\n",
    "        \n",
    "        class_label = np.zeros(height, width)\n",
    "        annids = voc_json.getAnnIds(imgIds=image_id)\n",
    "        anns = voc_json.loadAnns(annids)\n",
    "        for i in range(len(annids)):\n",
    "            mask = voc_json.annToMask(anns[i])\n",
    "            cate = anns[i]['category_id']\n",
    "            mask = mask * cate\n",
    "            class_label = class_label + mask\n",
    "        return class_label\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        '''Mapping annotation images to real Masks(MRCNN needed)\n",
    "        image_id: id of mask\n",
    "        Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        '''\n",
    "        PATH = os.path.join(ROOT_DIR, \"dataset/pascal_train.json\")\n",
    "        voc_json = COCO(PATH) # load training annotations\n",
    "        \n",
    "        annids = voc_json.getAnnIds(imgIds=image_id)\n",
    "        classes_ids = annids\n",
    "        anns = voc_json.loadAnns(annids)\n",
    "        masks = []\n",
    "        for i in range(len(annids)):\n",
    "            mask = voc_json.annToMask(anns[i])\n",
    "            mask = mask >= 1\n",
    "            masks.append(mask)\n",
    "        masks = np.array(masks)\n",
    "        return masks, classes_ids\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Inference\n",
    "############################################################\n",
    "\n",
    "def inference(model, dataset, limit):\n",
    "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
    "\n",
    "    # Create directory\n",
    "    if not os.path.exists(RESULTS_DIR):\n",
    "        os.makedirs(RESULTS_DIR)\n",
    "    time_dir = \"{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
    "    time_dir = os.path.join(RESULTS_DIR, time_dir)\n",
    "    os.makedirs(time_dir)\n",
    "\n",
    "    # Load over images\n",
    "    for image_id in dataset.image_ids[:limit]:\n",
    "        # Load image and run detection\n",
    "        image = dataset.load_image(image_id)\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        # Encode image to RLE. Returns a string of multiple lines\n",
    "        source_id = dataset.image_info[image_id][\"id\"]\n",
    "        # Save image with masks\n",
    "        if len(r['class_ids']) > 0:\n",
    "            print('[*] {}th image has {} instance(s).'.format(image_id, len(r['class_ids'])))\n",
    "            visualize.display_instances(\n",
    "                image, r['rois'], r['masks'], r['class_ids'],\n",
    "                dataset.class_names, r['scores'],\n",
    "                show_bbox=True, show_mask=True,\n",
    "                title=\"Predictions\")\n",
    "            plt.savefig(\"{}/{}\".format(time_dir, dataset.image_info[image_id][\"id\"]))\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.imshow(image)\n",
    "            plt.savefig(\"{}/noinstance_{}\".format(time_dir, dataset.image_info[image_id][\"id\"]))\n",
    "            print('[*] {}th image have no instance.'.format(image_id))\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    # Parse command line arguments\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Train Mask R-CNN on PASCAL VOC.')\n",
    "    parser.add_argument(\"command\",\n",
    "                        metavar=\"<command>\",\n",
    "                        help=\"'train' or 'inference' on PASCAL VOC\")\n",
    "    parser.add_argument('--dataset', required=False,\n",
    "                        metavar=\"/path/to/voc/\",\n",
    "                        help='Directory of the PASCAL VOC dataset')\n",
    "    parser.add_argument('--year', required=False,\n",
    "                        default=DEFAULT_DATASET_YEAR,\n",
    "                        metavar=\"<year>\",\n",
    "                        help='Year of the PASCAL VOC dataset (2007 or 2012) (default=2012)')\n",
    "    parser.add_argument('--model', required=True,\n",
    "                        metavar=\"/path/to/weights.h5\",\n",
    "                        help=\"Path to weights .h5 file or 'voc'\")\n",
    "    parser.add_argument('--logs', required=False,\n",
    "                        default=DEFAULT_LOGS_DIR,\n",
    "                        metavar=\"/path/to/logs/\",\n",
    "                        help='Logs and checkpoints directory (default=logs/)')\n",
    "    parser.add_argument('--limit', required=False,\n",
    "                        default=10,\n",
    "                        metavar=\"<image count>\",\n",
    "                        help='Images to use for evaluation (default=10)')\n",
    "\n",
    "    # TODO\n",
    "    '''\n",
    "    parser.add_argument('--download', required=False,\n",
    "                        default=False,\n",
    "                        metavar=\"<True|False>\",\n",
    "                        help='Automatically download and unzip PASCAL VOC files (default=False)',\n",
    "                        type=bool)\n",
    "    '''\n",
    "    args = parser.parse_args()\n",
    "    print(\"Command: \", args.command)\n",
    "    print(\"Model: \", args.model)\n",
    "    print(\"Dataset: \", args.dataset)\n",
    "    print(\"Year: \", args.year)\n",
    "    print(\"Logs: \", args.logs)\n",
    "    #print(\"Auto Download: \", args.download)\n",
    "\n",
    "\n",
    "    # Configurations\n",
    "    if args.command == \"train\":\n",
    "        config = VocConfig()\n",
    "    else:\n",
    "        config = InferenceConfig()\n",
    "    config.display()\n",
    "\n",
    "    # Create model\n",
    "    if args.command == \"train\":\n",
    "        model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "    else:\n",
    "        model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "\n",
    "\n",
    "    # Select weights file to load\n",
    "    if args.model.lower() == \"coco\":\n",
    "        model_path = COCO_WEIGHTS_PATH\n",
    "    elif args.model.lower() == \"last\":\n",
    "        # Find last trained weights\n",
    "        model_path = model.find_last()\n",
    "    elif args.model.lower() == \"imagenet\":\n",
    "        # Start from ImageNet trained weights\n",
    "        model_path = model.get_imagenet_weights()\n",
    "    else:\n",
    "        model_path = args.model\n",
    "\n",
    "    # Load weights\n",
    "    if args.model.lower() == \"coco\":\n",
    "        # Exclude the last layers because they require a matching\n",
    "        # number of classes\n",
    "        model.load_weights(model_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    else:\n",
    "        print(\"Loading weights \", model_path)\n",
    "        model.load_weights(model_path, by_name=True)\n",
    "\n",
    "\n",
    "    # Train or evaluate\n",
    "    if args.command == \"train\":\n",
    "        # Training dataset. Use the training set and 35K from the\n",
    "        # validation set, as as in the Mask RCNN paper.\n",
    "        dataset_train = VocDataset()\n",
    "        dataset_train.load_voc(args.dataset, \"train\", year=args.year)\n",
    "        dataset_train.prepare()\n",
    "\n",
    "        # Validation dataset\n",
    "        dataset_val = VocDataset()\n",
    "        dataset_val.load_voc(args.dataset, \"val\", year=args.year)\n",
    "        dataset_val.prepare()\n",
    "\n",
    "        # Image Augmentation\n",
    "        # Right/Left flip 50% of the time\n",
    "        augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "        # *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "        # Training - Stage 1\n",
    "        print(\"Training network heads\")\n",
    "        model.train(dataset_train, dataset_val,\n",
    "                    learning_rate=config.LEARNING_RATE,\n",
    "                    epochs=40,\n",
    "                    layers='heads',\n",
    "                    augmentation=augmentation)\n",
    "\n",
    "        # Training - Stage 2\n",
    "        # Finetune layers from ResNet stage 4 and up\n",
    "        print(\"Fine tune Resnet stage 4 and up\")\n",
    "        model.train(dataset_train, dataset_val,\n",
    "                    learning_rate=config.LEARNING_RATE,\n",
    "                    epochs=120,\n",
    "                    layers='4+',\n",
    "                    augmentation=augmentation)\n",
    "\n",
    "        # Training - Stage 3\n",
    "        # Fine tune all layers\n",
    "        print(\"Fine tune all layers\")\n",
    "        model.train(dataset_train, dataset_val,\n",
    "                    learning_rate=config.LEARNING_RATE / 10,\n",
    "                    epochs=160,\n",
    "                    layers='all',\n",
    "                    augmentation=augmentation)\n",
    "\n",
    "    elif args.command == \"inference\":\n",
    "        #print(\"evaluate have not been implemented\")\n",
    "        # Validation dataset\n",
    "        dataset_val = VocDataset()\n",
    "        voc = dataset_val.load_voc(args.dataset, \"val\", year=args.year)\n",
    "        dataset_val.prepare()\n",
    "        print(\"Running voc inference on {} images.\".format(args.limit))\n",
    "        inference(model, dataset_val, int(args.limit))\n",
    "    else:\n",
    "        print(\"'{}' is not recognized. \"\n",
    "              \"Use 'train' or 'inference'\".format(args.command))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
